\documentclass{article}

% We suggest
% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2020_tda}

% to compile a camera-ready version, add the [final] option, e.g.:
%\usepackage[final,nonatbib]{neurips_2020_tda}

% to avoid loading the natbib package, add option nonatbib:
\usepackage[nonatbib]{neurips_2020_tda}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{booktabs}       % professional-quality tables
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{microtype}      % microtypography
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{paralist}       % in-paragraph enumerations
\usepackage{siunitx}        % SI units
%%For figures and subcaptions
\usepackage[font=small]{caption}
\usepackage[labelformat=empty, position=top]{subcaption}
\usepackage{subcaption}
\usepackage[export]{adjustbox}

\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{microtype}
%\usepackage[draft]{fixme}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{mwe}
\usepackage{blkarray}

\usepackage{dcolumn,booktabs}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\newcommand\mc[1]{\multicolumn{1}{c}{#1}} % handy shortcut macro

\newsavebox{\tempbox}
\newlength{\tempwidth}


\usepackage[natbib,hyperref,sorting=none]{biblatex}
%\usepackage[backend=bibtex,doi=true,style=numeric,maxnames=3,maxbibnames=6]{biblatex}
\addbibresource{bibliography.bib}
%\renewcommand*{\bibfont}{\footnotesize}

\urlstyle{same}

\title{
  Simplicial Neural Networks
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Author \\
  Affiliation \\
  Address \\
  \texttt{email} \\
  % examples of more authors
  \And
  Author \\
  Affiliation \\
  Address \\
  \texttt{email} \\
  \And
  Author \\
  Affiliation \\
  Address \\
  \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}
\input{common.tex}
\begin{document}

\section*{TODOs and discussion}
General:
\begin{enumerate}
    \item \mdeff{I would define the convolution as a linear map that is a parameterized function of the Laplace--de Rham, i.e., $\varphi_W(\mathcal{L}) f$. That will (i) save space by staying basis-independent and avoiding the Fourier and eigencochain discussion (we can note that the basis that diagonalizes the operator is Fourier, but it shouldn't be central) and (ii) avoid the problematic definition we have now (i.e., that one cannot meaningfully convolve two cochains without a symmetry group). That way, the implementation of the functional as a truncated polynomial appears naturally, and we can list its nice properties: $O(n)$ computational cost, $O(1)$ learning complexity, and $N$-locality.}
    \item \mdeff{The saved space should be used to write more about the (co)boundary, and the dual (co)differential. The duality of taking the border or the derivative should be intuitive to anyone. Also add $B_0$ and/or $B_1$ to Figure 1. (If space allows, we could link to div/grad/curl for more intuition.)}
    \item \mdeff{Use it to explain how we link cochains of different degree. Maybe add a diagram of the SNN. (BTW we might want to consider the antiderivative $B^+$ instead of the codifferential $B\transpose$ to go down.)}
\end{enumerate}
Minor:
\begin{itemize}
    \item \mdeff{Can we have the figures in vector graphics (e.g., PDF) rather than PNG?}\stefania{Sure, I was planning to replot each figure as as soon as the writing was done.}
    \item \mdeff{I've done it here and there, but still more space can be saved by tightening the writing.}\stefania{Will do the same}
    \item \mdeff{Shall we use such a generic title? We may want to write a more comprehensive paper in the future.}\stefania{Any suggestion? I did not have anything in mind. I did not want to stress on the title something related to our computational results (I think what twe are selling here is rather the method) and in future work it can be proven to be useful for other dataset. PS Since we are submitting to a workshop the same paper- plus some additions- can be resubmitted to other journals or conferences.}
    \item \mdeff{There's a mix of Title Case and sentence case in section or paragraph headers. We should stick to one.}\stefania{Fixed this}
    \item \mdeff{Check for consistent terminology, e.g., node vs vertex.}\stefania{I'll do this}
\end{itemize}
\clearpage

\maketitle

\input{abstract.tex}

\input{introduction.tex}

\input{method.tex}

\input{experiments.tex}

\input{discussion.tex}

\printbibliography

\appendix

\input{supplementary.tex}

\end{document}
