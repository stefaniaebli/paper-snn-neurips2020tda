\section{Conclusion and future work}

We introduced a mathematical framework to design neural networks for data that live on simplicial complexes and provided preliminary results on their ability to impute missing data.
%We believe that SNNs provide a suitable analytic method for data that is intrinsically structured to represent $n$-fold interactions \mdeff{Empty sentence. And conclusion should be short.}
Future work might include: (i) comparing SNNs with state-of-the-art imputation algorithms, (ii) using SNNs to solve vector field problems, (iii) generalizing coarsening and pooling to simplicial complexes, (iv)using boundaries and coboundaries to map $p$-cochains to $(p-1)$-cochains and $(p+1)$-cochains either before or during convolution, and (iv) studying the expressive power of SNNs.
% as in~\cite{morris2019weisfeiler}. \mdeff{there's many papers}

% \mdeff{Larger outlook -> must leave an impression.}
Unrelated to the simplicial nature of this work, we would like to emphasize the way that the spectral language was key to developing and even formulating our method. In the same way that this view has often proven itself highly useful in extracting the important features of certain kinds of data (cf.\ the discipline of image compression), we believe it is underutilized in machine learning.
%Similarly, we wish to extend our method beyond Fourier-based filters, and wonder if there are gains to be had by for example wavelet filters, and whether they are natural in the context of simplicial complexes.
