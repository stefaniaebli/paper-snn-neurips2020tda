\section{Conclusion and future work}

We introduced a mathematical framework to design neural networks for data that live on simplicial complexes and provided preliminary results on their ability to impute missing data.
Future work might include:
(i) comparing SNNs with state-of-the-art imputation algorithms,
(ii) using SNNs to solve vector field problems,
(iii) generalizing coarsening and pooling to simplicial complexes,
(iv) using boundaries and coboundaries to mix data structured by relationships of different dimensions,
and (v) studying the expressive power of SNNs.

% \mdeff{Larger outlook -> must leave an impression.}
Unrelated to the simplicial nature of this work, we would like to emphasize the way that the spectral language was key to developing and even formulating our method. In the same way that this view has often proven itself highly useful in extracting the important features of certain kinds of data (cf.\ the discipline of image compression), we believe it is underutilized in machine learning.
%Similarly, we wish to extend our method beyond Fourier-based filters, and wonder if there are gains to be had by for example wavelet filters, and whether they are natural in the context of simplicial complexes.
