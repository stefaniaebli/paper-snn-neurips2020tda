\section{Conlusion and Future Work}

In this work we have introduced a new mathematical framework to design neural networks dealing with simplicial complex and showed preliminary results of their ability in imputing missing data. We believe that SNNs can provide a suitable method for data that is intrinsically structured to represent $n$-fold interactions.
Our future works will focus on two directions in the computational aspects:  i) applying the SNNs to vector field data ii) comparing the previous and new results with state of the art imputations algorithms, as in~\cite{spinelli2020neural}. 
In parallel, on the theoretical side we will investigate the following two problems: i) generalizing the processes of coarsening and pooling to SNNs. This will involve developing an efficient higher dimensional clustering algorithm for coarsening and to find a meaningful rearrangement of the clustered $k$-simplices for an efficient pooling ii) studying the expressive power of SNNs similarly to~\cite{morris2019weisfeiler}.

Unrelated to the simplicial nature of the work presented here, we would also like to emphasize the way that the spectral language was key to developing and even formulating our method. In the same way that this view has often proven itself highly useful in extracting the important features of certain kinds of data (cf.\ the disciplines of image and audio compression), we believe it is underutilized in machine learning. Similarly, we wish to extend our method beyond Fourier-based filters, and wonder if there are gains to be had by for example wavelet filters, and whether they are natural in the context of simplicial complexes.


